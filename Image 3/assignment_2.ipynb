{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fall 2024 AIN433 Assignment 2\n",
        "**Student:** Mehmet Ertaş - 2200765035\n",
        "\n",
        "**Instructor:** Ali Seydi Keçeli\n",
        "\n",
        "**TA:** Sibel Kapan"
      ],
      "metadata": {
        "id": "c5zIOXEwQXqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdM_7uwnPwi7",
        "outputId": "6aa14af2-6157-480a-9c48-e52e75887436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: opencv-contrib-python==3.4.2.16 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (3.4.2.16)\n",
            "Requirement not upgraded as not directly required: numpy>=1.11.3 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from opencv-contrib-python==3.4.2.16) (1.14.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "distributed 1.21.8 requires msgpack, which is not installed.\n",
            "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (0.13.1)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from scikit-image) (2.2.2)\n",
            "Requirement already satisfied: six>=1.7.3 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from scikit-image) (1.11.0)\n",
            "Requirement already satisfied: networkx>=1.8 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from scikit-image) (2.1)\n",
            "Requirement already satisfied: pillow>=2.1.0 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from scikit-image) (5.1.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from scikit-image) (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.7.1 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from matplotlib>=1.3.1->scikit-image) (1.14.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from matplotlib>=1.3.1->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from matplotlib>=1.3.1->scikit-image) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from matplotlib>=1.3.1->scikit-image) (2.7.3)\n",
            "Requirement already satisfied: pytz in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from matplotlib>=1.3.1->scikit-image) (2018.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from matplotlib>=1.3.1->scikit-image) (1.0.1)\n",
            "Requirement already satisfied: decorator>=4.1.0 in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from networkx>=1.8->scikit-image) (4.3.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\galip\\anaconda3.5\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->scikit-image) (39.1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "distributed 1.21.8 requires msgpack, which is not installed.\n",
            "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U opencv-contrib-python==3.4.2.16\n",
        "!pip install scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGcKsD3HPwjC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.measure import compare_ssim as ssim\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WTGi7EjPwjE"
      },
      "outputs": [],
      "source": [
        "def testSURF(img1):\n",
        "  compute = cv2.xfeatures2d.SURF_create()\n",
        "  keypoints, descriptors = compute.detectAndCompute(img1, None)\n",
        "  image_with_keypoints = cv2.drawKeypoints(img1, keypoints, None, color=(0, 255, 0), flags=0)\n",
        "\n",
        "  fig = plt.figure()\n",
        "  fig.set_size_inches(18,10)\n",
        "  plt.imshow(cv2.cvtColor(image_with_keypoints, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "img = cv2.imread(\"C:/Users/galip/Downloads/Panaromic_Dataset/p1/cyl_image00.png\", cv2.IMREAD_COLOR)\n",
        "testSURF(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-Anze2mPwjF"
      },
      "outputs": [],
      "source": [
        "def compute_homography(src_pts, dst_pts):\n",
        "  N = src_pts.shape[0]\n",
        "\n",
        "  H=[]\n",
        "  src_array = np.asarray(src_pts)\n",
        "  dst_array = np.asarray(dst_pts)\n",
        "\n",
        "  for n in range(N):\n",
        "    src = src_array[n]\n",
        "    H.append(-src[0])\n",
        "    H.append(-src[1])\n",
        "    H.append(-1)\n",
        "    H.append(0)\n",
        "    H.append(0)\n",
        "    H.append(0)\n",
        "\n",
        "  H = np.asarray(H)\n",
        "  H1 = H.reshape(2*N,3)\n",
        "\n",
        "  H2 = np.zeros([2*N, 3], dtype=int)\n",
        "  for i in range(0,2*N,2):\n",
        "    H2[i:i+2,0:i+3] = np.flip(H1[i:i+2,0:i+3], axis=0)\n",
        "\n",
        "  H2 = np.asarray(H2)\n",
        "  H3 = np.concatenate((H1, H2), axis=1)\n",
        "\n",
        "  H4=[]\n",
        "  for n in range(N):\n",
        "    src = src_array[n]\n",
        "    dst = dst_array[n]\n",
        "\n",
        "    H4.append(src[0]*dst[0])\n",
        "    H4.append(src[1]*dst[0])\n",
        "    H4.append(dst[0])\n",
        "    H4.append(src[0]*dst[1])\n",
        "    H4.append(src[1]*dst[1])\n",
        "    H4.append(dst[1])\n",
        "\n",
        "  H4 = np.asarray(H4)\n",
        "  H4 = H4.reshape(2*N,3)\n",
        "\n",
        "  H5 = np.concatenate((H3, H4), axis=1)\n",
        "  H8 = np.matmul(np.transpose(H5), H5)\n",
        "\n",
        "  w, v = np.linalg.eig(H8)\n",
        "  minimum = w.min()\n",
        "  for i in range(len(w)):\n",
        "    if w[i] == minimum:\n",
        "      a = v[:, i]\n",
        "\n",
        "  a = np.asarray(a)\n",
        "  a = a.reshape(3,3)\n",
        "  a = a/a[2,2]\n",
        "\n",
        "  return a\n",
        "\n",
        "\n",
        "def apply_homography(test, H):\n",
        "  dst_output = []\n",
        "  N = test.shape[0]\n",
        "\n",
        "  for row in test:\n",
        "    input = np.matrix([row[0,0], row[0,1], 1])\n",
        "    input = input.transpose()\n",
        "    mapped_pts = np.matmul(H, input)\n",
        "    dst_output.append(mapped_pts[0]/mapped_pts[2])\n",
        "    dst_output.append(mapped_pts[1]/mapped_pts[2])\n",
        "\n",
        "  dst_output = np.asarray(dst_output)\n",
        "  dst_output = dst_output.reshape(N, 2)\n",
        "\n",
        "  return dst_output\n",
        "\n",
        "def genMatchPairs(img1, img2):\n",
        "  compute = cv2.ORB_create(nfeatures=3000)\n",
        "  kp1, des1 = compute.detectAndCompute(cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY), None)\n",
        "  kp2, des2 = compute.detectAndCompute(cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY), None)\n",
        "  bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
        "  matches = bf.match(des1, des2)\n",
        "  matches = sorted(matches, key = lambda x:x.distance)\n",
        "\n",
        "  pts1 = np.zeros((250, 2))\n",
        "  pts2 = np.zeros((250, 2))\n",
        "  for i in range(250):\n",
        "    pts1[i,:] = kp1[matches[i].queryIdx].pt\n",
        "    pts2[i,:] = kp2[matches[i].trainIdx].pt\n",
        "\n",
        "  return pts1, pts2, matches[:250], kp1, kp2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvs1AmDtPwjG"
      },
      "outputs": [],
      "source": [
        "def RANSAC(Xs, Xd, max_iter, eps):\n",
        "  H = np.zeros([3,3])\n",
        "\n",
        "\n",
        "  inliers_ids = []\n",
        "  inliers_counts = []\n",
        "\n",
        "  n = Xs.shape[0]\n",
        "\n",
        "  iter = 0\n",
        "  while iter < max_iter:\n",
        "    inliers_id = []\n",
        "    pts_index = random.sample(range(0, n), 4)\n",
        "\n",
        "    Xs_new = []\n",
        "    Xd_new = []\n",
        "\n",
        "    for pt in range(4):\n",
        "      Xs_new.append(Xs[pts_index[pt]][:])\n",
        "      Xd_new.append(Xd[pts_index[pt]][:])\n",
        "\n",
        "    Xs_new = np.asarray(Xs_new)\n",
        "    Xd_new = np.asarray(Xd_new)\n",
        "    Xs_new = np.asmatrix(Xs_new)\n",
        "    Xd_new = np.asmatrix(Xd_new)\n",
        "\n",
        "    H = compute_homography(Xs_new, Xd_new)\n",
        "\n",
        "    Xs = np.asmatrix(Xs)\n",
        "    Xd_predicted = apply_homography(Xs, H)\n",
        "\n",
        "    for i in range(n):\n",
        "      SSD = ((round(Xd_predicted[i][0]) - int(Xd[i, 0]))**2 + (round(Xd_predicted[i][1]) - int(Xd[i, 1]))**2)\n",
        "\n",
        "      if SSD < eps:\n",
        "        if i not in inliers_id:\n",
        "          inliers_id.append(i)\n",
        "\n",
        "    inliers_ids.append(inliers_id)\n",
        "    inliers_counts.append(len(inliers_id))\n",
        "\n",
        "    iter += 1\n",
        "\n",
        "  largest_count_index = inliers_counts.index(max(inliers_counts))\n",
        "  best_inliers_id = inliers_ids[largest_count_index]\n",
        "\n",
        "  Xs_inliers = []\n",
        "  Xd_inliers = []\n",
        "  for i in best_inliers_id:\n",
        "    Xs_inliers.append(Xs[i][:])\n",
        "    Xd_inliers.append(Xd[i][:])\n",
        "\n",
        "  Xs_inliers = np.asarray(Xs_inliers)\n",
        "  Xd_inliers = np.asarray(Xd_inliers)\n",
        "  Xs_inliers = np.asmatrix(Xs_inliers)\n",
        "  Xd_inliers = np.asmatrix(Xd_inliers)\n",
        "\n",
        "  H = compute_homography(Xs_inliers, Xd_inliers)\n",
        "\n",
        "  return best_inliers_id, H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asf8V2lVPwjI"
      },
      "outputs": [],
      "source": [
        "def warp_img(src_img, H, dst_img_size):\n",
        "    M, N = dst_img_size\n",
        "    dst_img = np.zeros((M, N, src_img.shape[2]), dtype=src_img.dtype)\n",
        "\n",
        "    H_inv = np.linalg.inv(H)\n",
        "    for i in range(N):\n",
        "        for j in range(M):\n",
        "            src_coords = np.dot(H_inv, np.array([i, j, 1]))\n",
        "            src_coords /= src_coords[2]\n",
        "\n",
        "            src_x, src_y = src_coords[0], src_coords[1]\n",
        "\n",
        "            src_x = int(round(src_x))\n",
        "            src_y = int(round(src_y))\n",
        "\n",
        "\n",
        "            if 0 <= src_y < src_img.shape[0] and 0 <= src_x < src_img.shape[1]:\n",
        "                dst_img[j, i] = src_img[src_y, src_x]\n",
        "    return dst_img\n",
        "\n",
        "def binary_mask(img):\n",
        "    mask = (img[:, :, 0] > 0) | (img[:, :, 1] > 0) | (img[:, :, 2] > 0)\n",
        "    mask = mask.astype(\"int\")\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mco97hiVPwjI"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            img = cv2.imread(file_path)\n",
        "            if img is not None:\n",
        "                images.append(img)\n",
        "            else:\n",
        "                print(f\"Warning: Could not load image {file_path}\")\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrDlopE2PwjJ",
        "outputId": "80be9c6f-3461-4dee-9b88-952e9cb78346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 16 images.\n"
          ]
        }
      ],
      "source": [
        "folder_path = \"C:/Users/galip/Downloads/Panaromic_Dataset/p1\"\n",
        "\n",
        "images = load_images_from_folder(folder_path)\n",
        "print(f\"Loaded {len(images)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLHpWWGDPwjK",
        "outputId": "8008b418-b866-460d-d5a2-a9af57cc4f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image 0 loaded successfully with shape (480, 479, 3).\n",
            "Image 1 loaded successfully with shape (480, 479, 3).\n",
            "Image 2 loaded successfully with shape (480, 479, 3).\n",
            "Image 3 loaded successfully with shape (480, 479, 3).\n",
            "Image 4 loaded successfully with shape (480, 479, 3).\n",
            "Image 5 loaded successfully with shape (480, 479, 3).\n",
            "Image 6 loaded successfully with shape (480, 479, 3).\n",
            "Image 7 loaded successfully with shape (480, 479, 3).\n",
            "Image 8 loaded successfully with shape (480, 479, 3).\n",
            "Image 9 loaded successfully with shape (480, 479, 3).\n",
            "Image 10 loaded successfully with shape (480, 479, 3).\n",
            "Image 11 loaded successfully with shape (480, 479, 3).\n",
            "Image 12 loaded successfully with shape (480, 479, 3).\n",
            "Image 13 loaded successfully with shape (480, 479, 3).\n",
            "Image 14 loaded successfully with shape (480, 479, 3).\n",
            "Image 15 loaded successfully with shape (480, 479, 3).\n"
          ]
        }
      ],
      "source": [
        "for idx, img in enumerate(images):\n",
        "    if img is None or img.size == 0:\n",
        "        print(f\"Image {idx} is empty or could not be loaded.\")\n",
        "    else:\n",
        "        print(f\"Image {idx} loaded successfully with shape {img.shape}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXdGINLdPwjL"
      },
      "outputs": [],
      "source": [
        "def stitch_multiple(imgs):\n",
        "    stitched_img = np.pad(imgs[0], pad_width=((400, 400), (400, 400), (0, 0)), mode = \"constant\")\n",
        "\n",
        "    for i in range(1, len(imgs)):\n",
        "        current_img = imgs[i]\n",
        "        print(i)\n",
        "        if stitched_img.shape[:2] != current_img.shape[:2]:\n",
        "            current_img = resize_to_match(current_img, stitched_img.shape[:2])\n",
        "\n",
        "        pts1, pts2, matches1to2, kp1, kp2 = genMatchPairs(current_img, stitched_img)\n",
        "        inliers_idx, H = RANSAC(pts1, pts2, 500, 50)\n",
        "\n",
        "        warped_img = warp_img(current_img, H, [stitched_img.shape[0], stitched_img.shape[1]])\n",
        "\n",
        "        stitched_mask = 1 - binary_mask(warped_img)\n",
        "        stitched_mask = np.stack((stitched_mask,) * 3, -1)\n",
        "        stitched_img = np.multiply(stitched_img, stitched_mask) + warped_img\n",
        "\n",
        "        stitched_img = crop_to_content(stitched_img)\n",
        "\n",
        "    return stitched_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5saKP9yZPwjN",
        "outputId": "5faa978d-d993-4321-edb9-de96cb825021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(3.4.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-52-b690e92fe3c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Assuming 'images' is a list of images loaded in OpenCV (e.g., using cv2.imread)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinal_stitch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstitch_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Visualize the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-49-f36849a027a5>\u001b[0m in \u001b[0;36mstitch_multiple\u001b[1;34m(imgs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Perform feature matching and find the homography\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpts2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatches1to2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenSIFTMatchPairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstitched_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0minliers_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRANSAC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpts2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-51-56ab90661ebf>\u001b[0m in \u001b[0;36mgenSIFTMatchPairs\u001b[1;34m(img1, img2)\u001b[0m\n\u001b[0;32m     87\u001b[0m   \u001b[0mcompute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mORB_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m   \u001b[0mkp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m   \u001b[0mbf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBFMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNORM_L2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrossCheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m   \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<3,4,-1>,struct cv::Set<1,-1,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n"
          ]
        }
      ],
      "source": [
        "final_stitch = stitch_multiple(images)\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.imshow(cv2.cvtColor(final_stitch.astype(\"uint8\"), cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR7-rYnIPwjP"
      },
      "outputs": [],
      "source": [
        "def crop_to_content(img):\n",
        "    if len(img.shape) != 3 or img.shape[2] != 3:\n",
        "        raise ValueError(\"Input image must have 3 color channels (BGR).\")\n",
        "    gray = cv2.cvtColor(img.astype(\"uint8\"), cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
        "    x, y, w, h = cv2.boundingRect(thresh)\n",
        "    cropped_img = img[y:y+h, x:x+w]\n",
        "\n",
        "    return cropped_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y5VuGaNZPwjQ"
      },
      "outputs": [],
      "source": [
        "def resize_to_match(img, target_size):\n",
        "    return cv2.resize(img, (target_size[1], target_size[0]))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}